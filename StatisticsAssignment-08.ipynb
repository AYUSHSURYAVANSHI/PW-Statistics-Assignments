{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact \n",
    "# # the validity of the results.\n",
    "# # Answer :-\n",
    "# Analysis of Variance (ANOVA) is a statistical test used to compare means between two or more groups to determine if there are statistically significant differences among the group means. ANOVA is based on several assumptions, and violations of these assumptions can impact the validity of the results. The main assumptions for ANOVA are:\n",
    "\n",
    "# Independence: The observations within and between groups should be independent of each other. In other words, the value of one observation should not depend on the value of any other observation. Violations of independence could occur in longitudinal or repeated-measures designs, where measurements on the same subjects are correlated.\n",
    "\n",
    "# Normality: The data within each group should follow a normal distribution. Deviations from normality can lead to inaccurate p-values and confidence intervals. Violations could include skewed or heavy-tailed distributions. You can check normality using diagnostic plots or normality tests like the Shapiro-Wilk test.\n",
    "\n",
    "# Homogeneity of Variance (Homoscedasticity): The variances of the different groups should be approximately equal. If the variances are not equal, it can affect the test's power and lead to incorrect conclusions. Violations could result from unequal variances in different groups, which can be detected using statistical tests or visual inspection of variance-covariance matrices.\n",
    "\n",
    "# Independence of Errors: The residuals (differences between the observed values and the predicted values) should be independent of each other and exhibit no systematic patterns. Serial correlation in the residuals can be a violation of this assumption, potentially affecting the validity of the test.\n",
    "\n",
    "# Examples of Violations and Their Impact:\n",
    "\n",
    "# Non-Normality: If the data within groups do not follow a normal distribution, ANOVA results may not be valid. The impact can include incorrect p-values and confidence intervals, leading to the risk of false positives or false negatives. For example, if the data is heavily skewed, ANOVA may incorrectly indicate significant differences.\n",
    "\n",
    "# Heteroscedasticity: When the variances in different groups are unequal, ANOVA may be less powerful in detecting true group differences or may erroneously detect differences that do not exist. This can lead to Type I or Type II errors. For instance, if one group has much larger variances than others, ANOVA may incorrectly conclude that there are significant group differences.\n",
    "\n",
    "# Violations of Independence: In longitudinal or repeated-measures designs, where observations within the same subject are correlated, the independence assumption is violated. This can result in inflated Type I errors or an increased likelihood of detecting significant differences even when they don't exist.\n",
    "\n",
    "# To address these violations, there are alternative tests and methods available. For example, non-parametric tests like the Kruskal-Wallis test can be used when the assumption of normality is violated, and Welch's ANOVA can be employed when homogeneity of variances is not met. Additionally, transformations or robust ANOVA methods can sometimes mitigate the impact of these violations. It's important to assess the assumptions and choose the appropriate test based on the characteristics of your data to ensure the validity of your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "# # Answer :-\n",
    "\n",
    "# Analysis of Variance (ANOVA) is a statistical technique used to compare means across two or more groups to determine if there are significant differences. There are three main types of ANOVA, each suited for different situations:\n",
    "\n",
    "# One-Way ANOVA:\n",
    "\n",
    "# Use Case: One-Way ANOVA is used when you have one categorical independent variable (with more than two levels or groups) and a continuous dependent variable.\n",
    "# Example: You want to compare the mean test scores of students from three different schools (School A, School B, and School C) to determine if there are significant differences in the academic performance between the schools. Here, the independent variable is the school, and the dependent variable is the test score.\n",
    "# Two-Way ANOVA:\n",
    "\n",
    "# Use Case: Two-Way ANOVA is used when you have two categorical independent variables (factors) and one continuous dependent variable. It allows you to assess the interaction effects between the two independent variables.\n",
    "# Example: You want to determine if both the type of diet (Factor A: Diet A, Diet B) and the gender of participants (Factor B: Male, Female) have significant effects on weight loss (the dependent variable). Two-Way ANOVA will help you analyze the main effects of diet and gender as well as their interaction effect.\n",
    "# Repeated Measures ANOVA:\n",
    "\n",
    "# Use Case: Repeated Measures ANOVA is used when you have one group of participants and you measure the same dependent variable under multiple conditions or at different time points. It is essentially an extension of One-Way ANOVA for within-subject designs.\n",
    "# Example: You want to evaluate the impact of a new drug on patients' blood pressure. You measure their blood pressure before taking the drug, immediately after taking it, and then at 30-minute intervals for the next two hours. Repeated Measures ANOVA is appropriate because the same participants are measured under different conditions over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "# # Answer :-\n",
    "# The partitioning of variance in Analysis of Variance (ANOVA) is a fundamental concept that helps us understand the sources of variation in a dataset. It decomposes the total variation in the data into different components, allowing us to assess the relative contributions of these components and make inferences about group means. Understanding this concept is essential in ANOVA for several reasons:\n",
    "\n",
    "# Identification of Sources of Variation:\n",
    "\n",
    "# Partitioning of variance allows us to identify and separate the different sources of variation in the data. This includes variation within groups and variation between groups (or factors). By understanding where the variation comes from, we can assess the impact of each source on the outcome variable.\n",
    "# Hypothesis Testing:\n",
    "\n",
    "# ANOVA involves testing hypotheses about group means. The partitioning of variance is critical for hypothesis testing, as it provides a way to compare the variation between groups (treatment effect) with the variation within groups (random variability). This comparison is used to calculate the F-statistic and assess the statistical significance of group differences.\n",
    "# Estimation of Group Means:\n",
    "\n",
    "# By partitioning the variance and assessing the group differences, ANOVA allows us to estimate the means of different groups. This estimation is useful for understanding the central tendencies of groups and making comparisons between them.\n",
    "# Understanding Group Differences:\n",
    "\n",
    "# ANOVA helps us answer questions about whether the means of the groups are significantly different from each other. The partitioning of variance helps us understand whether observed differences are likely due to the treatment or factors being studied or if they could have occurred by chance.\n",
    "# Assessing the Model Fit:\n",
    "\n",
    "# Partitioning of variance can be used to assess how well the model (ANOVA model) fits the data. It helps in evaluating the goodness of fit by comparing the explained variance (variation between groups) with the unexplained variance (variation within groups).\n",
    "# Model Diagnostics:\n",
    "\n",
    "# Understanding the partitioning of variance is crucial for model diagnostics. It allows researchers to identify any issues with the assumptions of the ANOVA, such as violations of homogeneity of variances or normality.\n",
    "# Interpretation and Reporting:\n",
    "\n",
    "# When presenting ANOVA results, understanding the partitioning of variance is essential for proper interpretation. Researchers can explain the proportion of variance explained by the factors or treatments, which is important for communicating the practical significance of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual \n",
    "# sum of squares (SSR) in a one-way ANOVA using Python?\n",
    "# Answer :-\n",
    "# Group data (replace with your data and groupings)\n",
    "group_1 = [45, 52, 48]\n",
    "group_2 = [55, 50, 58]\n",
    "group_3 = [51, 54, 49, 47]\n",
    "\n",
    "# Calculate the group means\n",
    "mean_group_1 = np.mean(group_1)\n",
    "mean_group_2 = np.mean(group_2)\n",
    "mean_group_3 = np.mean(group_3)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "SSE = len(group_1) * (mean_group_1 - overall_mean)**2 + len(group_2) * (mean_group_2 - overall_mean)**2 + len(group_3) * (mean_group_3 - overall_mean)**2\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "SSR = sum((x - np.mean(group_1))**2 for x in group_1) + sum((x - np.mean(group_2))**2 for x in group_2) + sum((x - np.mean(group_3))**2 for x in group_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?\n",
    "# Answer :-\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset into a DataFrame (replace with your data)\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Perform a two-way ANOVA\n",
    "model = stats.ols('Y ~ A * B', data=data).fit()\n",
    "anova_table = stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the F-statistics and p-values\n",
    "F_A = anova_table['F']['A']\n",
    "p_A = anova_table['PR(>F)']['A']\n",
    "\n",
    "F_B = anova_table['F']['B']\n",
    "p_B = anova_table['PR(>F)']['B']\n",
    "\n",
    "F_interaction = anova_table['F']['A:B']\n",
    "p_interaction = anova_table['PR(>F)']['A:B']\n",
    "\n",
    "print(f\"Main Effect A: F = {F_A}, p-value = {p_A}\")\n",
    "print(f\"Main Effect B: F = {F_B}, p-value = {p_B}\")\n",
    "print(f\"Interaction Effect (A:B): F = {F_interaction}, p-value = {p_interaction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. \n",
    "# # What can you conclude about the differences between the groups, and how would you interpret these \n",
    "# # results?\n",
    "# #  Answer :-\n",
    "# In a one-way Analysis of Variance (ANOVA), the F-statistic and its associated p-value are used to determine whether there are significant differences between the group means. In your scenario, you obtained an F-statistic of 5.23 and a p-value of 0.02. Here's how to interpret these results:\n",
    "\n",
    "# The F-Statistic (5.23):\n",
    "\n",
    "# The F-statistic is a measure of the ratio of the variance between groups (explained variance) to the variance within groups (unexplained variance). A higher F-statistic suggests a larger difference between the group means relative to the variability within each group.\n",
    "# The P-Value (0.02):\n",
    "\n",
    "# The p-value represents the probability of obtaining an F-statistic as extreme as the one observed (or more extreme) if there were no real differences between the groups. In other words, it assesses whether the observed differences are statistically significant.\n",
    "# Interpretation:\n",
    "\n",
    "# Based on the F-statistic and p-value:\n",
    "\n",
    "# Statistical Significance: The p-value of 0.02 is less than the chosen significance level (alpha), which is typically set at 0.05. This indicates that the differences between the groups are statistically significant.\n",
    "\n",
    "# Conclusions: You can conclude that there are significant differences between the groups in the population from which the samples were drawn.\n",
    "\n",
    "# Post-hoc Tests: If your one-way ANOVA indicates significant group differences, you may want to perform post-hoc tests (e.g., Tukey's HSD, Bonferroni, or Dunnett's test) to identify which specific group means are different from each other. These post-hoc tests can provide more detailed information about pairwise group comparisons.\n",
    "\n",
    "# Effect Size: While the F-statistic and p-value indicate statistical significance, it's also valuable to assess the practical significance or effect size. An effect size measure (e.g., eta-squared or Cohen's d) can help quantify the magnitude of the differences between the groups, providing a more meaningful interpretation of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential \n",
    "# # consequences of using different methods to handle missing data?\n",
    "# # Answer:-\n",
    "# Handling missing data in a repeated measures ANOVA is an important aspect of data analysis. Repeated measures ANOVA, which is used when the same subjects are measured under multiple conditions or time points, can be sensitive to missing data. Here's how you can handle missing data and the potential consequences of using different methods:\n",
    "\n",
    "# Listwise Deletion (Complete Case Analysis):\n",
    "\n",
    "# Handling: In listwise deletion, any subject with missing data on any of the measured conditions or time points is excluded from the analysis.\n",
    "# Consequences:\n",
    "# Pros: Simple and straightforward.\n",
    "# Cons: Reduces sample size, which can reduce statistical power and may introduce selection bias if missing data is not completely random.\n",
    "# Imputation:\n",
    "\n",
    "# Handling: Imputation involves filling in missing values with estimated values. Common imputation methods include mean imputation (replacing missing values with the group mean), linear interpolation, last observation carried forward, or using statistical imputation techniques such as multiple imputation.\n",
    "# Consequences:\n",
    "# Pros: Retains all subjects in the analysis, maintains sample size, and may provide less biased estimates.\n",
    "# Cons: Can introduce measurement error or bias if the imputation method is not appropriate or if the assumption of data missing at random (MAR) is violated. Imputation methods may also obscure the true variability in the data.\n",
    "# Maximum Likelihood Estimation (MLE):\n",
    "\n",
    "# Handling: MLE is a statistical approach that estimates model parameters by maximizing the likelihood function. In the context of repeated measures ANOVA, MLE is used to estimate parameters while accounting for missing data.\n",
    "# Consequences:\n",
    "# Pros: Utilizes all available information, provides unbiased estimates, and is the preferred method when data is missing at random (MAR).\n",
    "# Cons: May not perform well when data is not missing at random (NMAR) or when the assumptions of the model are violated. MLE can be computationally intensive and requires specialized software.\n",
    "# Potential Consequences of Different Methods:\n",
    "\n",
    "# Using listwise deletion can result in reduced statistical power and biased estimates if missing data is not completely random. It may lead to a loss of valuable information, especially in small sample sizes.\n",
    "\n",
    "# Imputation can help maintain sample size and reduce bias if done correctly. However, it can introduce error if the imputation method is inappropriate, and it may not be valid if data is not missing at random.\n",
    "\n",
    "# Maximum Likelihood Estimation is generally the preferred method as it provides unbiased estimates and utilizes all available information. However, it relies on assumptions of normality and may be sensitive to model misspecification. It is also computationally demanding.\n",
    "\n",
    "# The choice of how to handle missing data should be made carefully, taking into consideration the nature of the data, the assumptions of the analysis, and the potential consequences of the chosen method. It's important to document and justify the approach taken to handle missing data in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide \n",
    "# # an example of a situation where a post-hoc test might be necessary.\n",
    "# # Answer :-\n",
    "# Post-hoc tests are used in conjunction with Analysis of Variance (ANOVA) when you have three or more groups, and the ANOVA results indicate that there are significant differences between at least some of the group means. Post-hoc tests are performed to make pairwise comparisons between specific groups to identify which groups differ from each other. Some common post-hoc tests include:\n",
    "\n",
    "# Tukey's Honestly Significant Difference (Tukey's HSD):\n",
    "\n",
    "# Use Case: Tukey's HSD is widely used when you have equal group sizes and homogeneity of variances. It controls the familywise error rate, making it suitable for exploratory analyses when you want to identify all significantly different pairs.\n",
    "# Example: In a study comparing the effectiveness of four different teaching methods (A, B, C, D) on student test scores, you use Tukey's HSD to identify which teaching methods yield significantly different scores.\n",
    "# Bonferroni Correction:\n",
    "\n",
    "# Use Case: Bonferroni is conservative and suitable when you want to control the familywise error rate, especially when making multiple comparisons. It is commonly used when you have unequal group sizes and/or heterogeneity of variances.\n",
    "# Example: In a clinical trial, you want to compare the efficacy of four different drug treatments to a control group. To maintain an overall alpha level of 0.05, you use the Bonferroni correction to adjust individual comparison p-values.\n",
    "# Sidak Correction:\n",
    "\n",
    "# Use Case: Similar to Bonferroni, Sidak correction is used to control the familywise error rate when making multiple comparisons. It may be less conservative than Bonferroni and is suitable for situations with unequal group sizes and heterogeneity of variances.\n",
    "# Example: In a market research study, you want to compare the average purchase amounts among several customer segments. You use Sidak correction to make pairwise comparisons between the segments while controlling the overall alpha level.\n",
    "# Dunnett's Test:\n",
    "\n",
    "# Use Case: Dunnett's test is used when you have a control group and you want to compare other groups to the control. It controls the familywise error rate and is commonly used in experimental and clinical trials.\n",
    "# Example: In a drug trial, you have a control group and three experimental groups receiving different drug dosages. You use Dunnett's test to compare each experimental group to the control group while controlling for multiple comparisons.\n",
    "# Fisher's Least Significant Difference (LSD):\n",
    "\n",
    "# Use Case: Fisher's LSD is used when you have equal group sizes and homogeneity of variances. It's a relatively liberal test, and it's appropriate when you have a priori hypotheses about specific pairwise comparisons.\n",
    "# Example: In an agricultural study, you have data on crop yields for five different fertilizers. You use Fisher's LSD to test specific pairwise comparisons you have a theoretical basis to investigate.\n",
    "# Games-Howell:\n",
    "\n",
    "# Use Case: Games-Howell is a non-parametric post-hoc test that can be used when the assumptions of equal variances and normality are violated. It's robust to unequal group sizes.\n",
    "# Example: In a psychological study, you want to compare the reaction times of participants across various experimental conditions. If the data distribution is not normal and variances are unequal, you can use Games-Howell for post-hoc tests.\n",
    "# The choice of a post-hoc test depends on the specific characteristics of your data, such as group sizes, homogeneity of variances, and your research objectives. It's essential to select a post-hoc test that is appropriate for your data and control the familywise error rate when making multiple comparisons to maintain the overall Type I error rate.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from \n",
    "# 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python \n",
    "# to determine if there are any significant differences between the mean weight loss of the three diets. \n",
    "# Report the F-statistic and p-value, and interpret the results.\n",
    "# Answer :-\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "# Sample data for the three diets (replace with your actual data)\n",
    "diet_A = [2.0, 3.0, 1.5, 2.5, 2.3, 3.1, 2.2, 1.8, 2.9, 1.7]\n",
    "diet_B = [3.2, 2.7, 3.5, 3.0, 2.8, 3.3, 2.6, 3.4, 2.4, 3.1]\n",
    "diet_C = [1.1, 0.9, 1.2, 1.0, 1.5, 1.3, 1.4, 1.7, 0.8, 1.6]\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([diet_A, diet_B, diet_C])\n",
    "\n",
    "# Create a corresponding grouping variable\n",
    "group_labels = ['A'] * len(diet_A) + ['B'] * len(diet_B) + ['C'] * len(diet_C)\n",
    "\n",
    "# Perform the one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report the results\n",
    "print(f\"F-statistic: {f_statistic:.2f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The one-way ANOVA is significant, indicating that there are significant differences in mean weight loss between at least two of the three diets.\")\n",
    "else:\n",
    "    print(\"The one-way ANOVA is not significant, suggesting that there are no significant differences in mean weight loss between the three diets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q10. A company wants to know if there are any significant differences in the average time it takes to \n",
    "# complete a task using three different software programs: Program A, Program B, and Program C. They \n",
    "# randomly assign 30 employees to one of the programs and record the time it takes each employee to \n",
    "# complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or \n",
    "# interaction effects between the software programs and employee experience level (novice vs. \n",
    "# experienced). Report the F-statistics and p-values, and interpret the results.\n",
    "# Answer :-\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "data = pd.read_csv('your_data.csv')  # Assuming you have a CSV file with columns: 'Software', 'Experience', 'Time'\n",
    "\n",
    "# Perform a two-way ANOVA\n",
    "model = stats.ols('Time ~ Software * Experience', data=data).fit()\n",
    "anova_table = stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract the F-statistics and p-values\n",
    "F_software = anova_table['F']['Software']\n",
    "p_software = anova_table['PR(>F)']['Software']\n",
    "\n",
    "F_experience = anova_table['F']['Experience']\n",
    "p_experience = anova_table['PR(>F)']['Experience']\n",
    "\n",
    "F_interaction = anova_table['F']['Software:Experience']\n",
    "p_interaction = anova_table['PR(>F)']['Software:Experience']\n",
    "\n",
    "# Report the results\n",
    "print(f\"Main Effect of Software: F = {F_software:.2f}, p-value = {p_software:.4f}\")\n",
    "print(f\"Main Effect of Experience: F = {F_experience:.2f}, p-value = {p_experience:.4f}\")\n",
    "print(f\"Interaction Effect (Software * Experience): F = {F_interaction:.2f}, p-value = {p_interaction:.4f}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "\n",
    "if p_software < alpha:\n",
    "    print(\"There is a significant main effect of Software, indicating that at least one software program has a different average completion time.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Software.\")\n",
    "\n",
    "if p_experience < alpha:\n",
    "    print(\"There is a significant main effect of Experience, suggesting that novice and experienced employees have different average completion times.\")\n",
    "else:\n",
    "    print(\"There is no significant main effect of Experience.\")\n",
    "\n",
    "if p_interaction < alpha:\n",
    "    print(\"There is a significant interaction effect between Software and Experience, indicating that the effect of software programs on completion time depends on the employees' experience level.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between Software and Experience.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q11. An educational researcher is interested in whether a new teaching method improves student test \n",
    "# scores. They randomly assign 100 students to either the control group (traditional teaching method) or the \n",
    "# experimental group (new teaching method) and administer a test at the end of the semester. Conduct a \n",
    "# two-sample t-test using Python to determine if there are any significant differences in test scores \n",
    "# between the two groups. If the results are significant, follow up with a post-hoc test to determine which \n",
    "# group(s) differ significantly from each other.\n",
    "# Answer :-\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "data = pd.read_csv('your_data.csv')  # Assuming you have a CSV file with columns: 'Group' (Control or Experimental), 'Test_Score'\n",
    "\n",
    "# Separate the data into two groups\n",
    "control_group = data[data['Group'] == 'Control']['Test_Score']\n",
    "experimental_group = data[data['Group'] == 'Experimental']['Test_Score']\n",
    "\n",
    "# Perform the two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Report the results\n",
    "print(f\"T-Statistic: {t_statistic:.2f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The two-sample t-test is significant, indicating that there are significant differences in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"The two-sample t-test is not significant, suggesting that there are no significant differences in test scores between the groups.\")\n",
    "\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Combine the data for post-hoc testing\n",
    "all_scores = data['Test_Score']\n",
    "\n",
    "# Create a grouping variable\n",
    "group_labels = data['Group']\n",
    "\n",
    "# Perform Tukey's HSD post-hoc test\n",
    "tukey_result = pairwise_tukeyhsd(endog=all_scores, groups=group_labels, alpha=0.05)\n",
    "\n",
    "# Display the post-hoc results\n",
    "print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q12. A researcher wants to know if there are any significant differences in the average daily sales of three \n",
    "# retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store \n",
    "# on those days. Conduct a repeated measures ANOVA using Python to determine if there are any \n",
    "# significant differences in sales between the three stores. If the results are significant, follow up with a post\n",
    "# hoc test to determine which store(s) differ significantly from each other.\n",
    "# Answer :-\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# Sample data (replace with your actual data)\n",
    "data = pd.read_csv('your_data.csv')  # Assuming you have a CSV file with columns: 'Store' (A, B, or C), 'Day', 'Sales'\n",
    "\n",
    "# Perform a repeated measures ANOVA\n",
    "rm_anova = AnovaRM(data, 'Sales', 'Day', within=['Store'])\n",
    "results = rm_anova.fit()\n",
    "\n",
    "# Report the results\n",
    "print(results)\n",
    "\n",
    "from statsmodels.sandbox.stats.multicomp import MultiComparison\n",
    "\n",
    "# Perform pairwise t-tests with Bonferroni correction\n",
    "mc = MultiComparison(data['Sales'], data['Store'])\n",
    "result = mc.allpairtest(stats.ttest_rel, method='bonf')\n",
    "print(result[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
